---
# Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
title: "Vespa information flow"
---

<p>
This document details how information moves through a Vespa system.
</p>


<h2 id="when-deploying-an-application">...when deploying an application</h2>
<p>
"deploying an application" means running the command
<code><a href="../cloudconfig/application-packages.html#deploy">vespa-deploy prepare</a></code>.
Its task is to make all configuration files and application code available to all hosts in the system.
It does this by parsing the hand-written configuration and deriving separate configuration files for each node,
which is then accessible through the
<code><a href="../cloudconfig/configuration-server.html">config-server</a></code> service on the configserver node.
Refer to <a href="../config-sentinel.html">Vespa startup</a>.
<ol>
  <li>Read system configuration
    <ol type="a">
      <li>
        Read <a href="hosts.html">hosts.xml</a> to setup
        <em>one or more</em> aliases for each host that is used in <code>services.xml</code>.
      </li><li>
        Read <a href="services.html">services.xml</a>,
        and run each child node of <code>&lt;services&gt;</code> through a separate XML parser
        (i.e. <code>&lt;admin&gt;</code>, <code>&lt;container&gt;</code>
        and <code>&lt;content&gt;</code> are parsed by separate parsers).
        This makes the configuration framework easily extendable.
        The XML syntax and structure is also validated against a set of schema files.
      </li><li>
        Read all search definitions that are referenced in <code>services.xml</code> from
        directory <code>searchdefinitions/</code>.
        These definitions are parsed to build machine-understandable indexing language scripts
        (see <a href="../search-definitions.html">search definitions</a>)
        that the indexing document processor uses to perform indexing of documents.
      </li>
    </ol>
  </li>
  <li>Produce all configuration needed for every service in the entire application.
    <ol type="a">
      <li>
        All generated files are stored in directory
        <code>$VESPA_HOME/var/db/vespa/config_server/serverdb/configs/</code>
        for distribution through the configserver interface.
      </li><li>
        The same data is stored in <a href="../cloudconfig/configuration-server.html">ZooKeeper</a>.
      </li>
    </ol>
  </li>
</ol>
At this point all configuration files and their derivates are available on disk
and in the ZooKeeper data storage system of the configserver.
The configserver takes no notice of these files until <code>vespa-deploy activate</code> is run.
</p><p>
<code><a href="cloudconfig/application-packages.html#deploy">vespa-deploy activate</a></code>
forces the <code>config-server</code> on every configserver node to
reload all configuration files from the most recently deployed set of data in ZooKeeper.
All configurations are then propagated to those processes that subscribe to them.
</p>



<h2 id="when-feeding-an-application">...when feeding an application</h2>
<p>
"Feeding an application" means sending a set of documents to Vespa for indexing.
Receiving these documents and relaying these to the designated search nodes happens in accordance with figure 2:
</p>
<ol>
<li>
  The user initiates a feed to a <a href="../routing.html">named route</a> either through
  <ol type="a">
    <li>
      a <a href="../document-api-guide.html">Document API</a> client
      that communicates with a document processing cluster, or
    </li>
    <li>
      the binary <code>vespa-feeder</code>, or
    </li>
    <li>
      the <a href="../api.html">HTTP APIs</a>
    </li>
  </ol>
</li>
<li>
  The Document API contains the necessary logic to distribute the document stream to all of the available
  document processor nodes in the selected cluster in a round-robin fashion.
</li><li>
  Each document processor node is running a java server called <code>com.yahoo.docproc.server.Server</code>.
  This service, like all other services, receives its configuration
  from the local <code>config-proxy</code> by subscription.
</li><li>
  <code>com.yahoo.docproc.server.Server</code> processes the documents it receives according to its
  <a href="services-docproc.html">configuration</a>.
  Each document is distributed to all search nodes in the column that corresponds to the document's hash.
</li>
</ol>
<p align="center">
<img src="../img/reference/flow/feed1.png" /><br />
<strong>Figure 2:</strong> Information flow in Vespa when feeding an application
</p><p>
As the distributor relays an incoming document stream to a search node,
the information is carried according to figure 3:
</p>
<ol>
  <li>
    The data stream enters a search cluster by direct connection to the
    <code><a href="../proton.html">vespa-proton</a></code>-process running on its content-nodes;
    there is no controller within the cluster that has to acknowledge or verify the data.
    <code>vespa-proton</code> indexes the data immediately and as soon as the response is sent back to the feeder,
    the document is searchable.
  </li>
</ol>
<p align="center">
<img src="../img/reference/flow/feed2.png" /><br />
<strong>Figure 3:</strong> Information flow in Vespa when feeding an application, detail of search cluster
</p>



<h2 id="query">...when querying from an application</h2>
<p>
By "querying from an application" we mean an action by a user to search through the set of documents
that has already been fed to and indexed.
The query exists as a human readable string similar to what any user of a search engine could write.
</p><p>
Information moves through the system according to figure 4:
</p>
<ol>
  <li>
    A query arrives from a front-end application to one of several Query Result Server nodes (QRS).
    The node that is used is given by the front-end, and is of no concern to Vespa -
    if a QRS is down, it is up to the front-end to relay the query to one of the other nodes.
  </li><li>
    Any required processing of the query is done by the <code>qrs</code>-binary itself.
    This includes narrowing down of the search, such as stemming and geo-tagging.
  </li><li>
    Unless otherwise specified by the query, it is distributed by the QRS to all search clusters in the system.
    Because the selection of top level dispatcher (TLD) is done by a hash of the query,
    it is viable to cache query-results even on TLD's.
  </li>
</ol>
<p align="center">
<img src="../img/reference/flow/query1.png" /><br />
<strong>Figure 4:</strong> Information flow in Vespa when querying from an application
</p><p>
At this point the query enters one or more search clusters, and information flows according to figure 5:
</p>
<ol>
  <li>
    Like all services in Vespa, the dispatcher service (with binary <code>vespa-dispatch</code>)
    is run by the <code>vespa-config-sentinel</code>.
    This service subscribes to its configuration from the local <code>config-proxy</code>,
    and its primary task is to relay the query such that it covers the entire document base,
    with the lowest possible maximum load on its relevant search nodes.
    The TLD knows what queries are being processed and at which nodes,
    and load balancing is done by dispatching to the node with the lowest number of running queries.
    <ol type="a">
      <li>
        The query arrives at each searchnode's local dispatcher
        (binary is the same as for TLD, <code>vespa-dispatch</code>).
        This dispatcher allocates search threads in binary
        <code>vespa-proton</code> to perform a search in the local index for the query.
        The two modes of the <code>vespa-dispatch</code> binary are separable in the log files by their entry;
        the search node writes:
<pre>
(...) searchnode.dispatch0.dispatch
vespa-dispatch (...)
</pre>
        whereas the top level dispatcher writes:
<pre>
(...)
topleveldispatch vespa-dispatch (...)
</pre>

      </li><li>
        <code>vespa-proton</code> searches its memory index or the local disk index files in
        <code>$VESPA_HOME/var/db/vespa/search/</code> and returns its results back to the local dispatcher.
      </li>
    </ol>
  </li><li>
    When all search nodes have responded to the TLD, it merges their partial results
    and relays this back to the QRS.
  </li><li>
    The QRS performs any required processing of the results, possibly requerying data if needed,
    before it finally returns these to the querying entity.
  </li>
</ol>
<p align="center">
<img src="../img/reference/flow/query2.png" /><br />
<strong>Figure 5:</strong> Information flow in Vespa when querying from an application, detail of search cluster
</p>
