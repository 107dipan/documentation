---
# Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
title: "Vespa HTTP Benchmarking Tool - vespa-fbench"
---

<p>
This is the HTML version of the man page for the command line tool <em>vespa-fbench</em> -
a tool used for benchmarking the capacity of a Vespa system. Description:
<ul>
  <li>Several hostnames and ports can be listed</li>
  <!-- ToDo: make sure we have an example using multiple hosts -->
  <li>This is distributed in round-robin manner to clients</li>
</ul>
</p>


<h2 id="synopsis">Synopsis</h2>
<p>
<strong>vespa-fbench</strong> [options] &lt;hostname&gt; &lt;port&gt;
</p>


<h2 id="options">Options</h2>

<table class="table">
  <thead></thead><tbody>
    <tr>

<th>-H <em>header</em></th>
<td>
append extra header to each get request.
</td>
    </tr><tr>

<th>-A <em>assign autority</em></th>
<td>
<str> hostname:port. Overrides Host: header sent.
</td>
    </tr><tr>

<th>-P</th>
<td>
use POST for requests instead of GET
</td>
</tr><tr>

<th>-a <em>str</em></th>
<td>
append string to each query
</td>
    </tr><tr>

<th style="width:200px">-n <em>numClients</em></th>
<td>
Run vespa-fbench with <em>numClients</em> clients in parallel.  If not
specified, vespa-fbench will use a default value of <em>10</em> clients.
</td>
    </tr><tr>
      
<th>-c <em>cycleTime</em></th>
<td>
each client will make a request each &lt;num&gt; milliseconds [1000]
('-1' -&gt; cycle time should be twice the response time)
</td>
    </tr><tr>

<th>-l <em>limit</em></th>
<td>
minimum response size for successful requests [0]
</td>
    </tr><tr>

<th>-i <em>ignoreCount</em></th>
<td>
do not log the &lt;num&gt; first results. -1 means no logging [0]
</td>
    </tr><tr>

<th>-s <em>seconds</em></th>
<td>
run the test for &lt;num&gt; seconds. -1 means forever [60]
</td>
    </tr><tr>

<th>-q <em>queryFilePattern</em></th>
<td>
pattern defining input query files ['query%03d.txt'] (the pattern is
            used with sprintf to generate filenames)
</td>
    </tr><tr>

<th>-o <em>outputFilePattern</em></th>
<td>
save query results to output files with the given pattern (default is
            not saving.)
</td>
    </tr><tr>

<th>-r <em>restartLimit</em></th>
<td>
 number of times to re-use each query file. -1 means no limit [-1]
</td>
    </tr><tr>

<th>-m <em>maxLineSize</em></th>
<td>
max line size in input query files [8192].  Can not be less than the
            minimum [1024].
</td>
    </tr><tr>

<th>-p <em>seconds</em></th>
<td>
print summary every &lt;num&gt; seconds.  only available when
installing vespa-fbench from test branch,
</td>
    </tr><tr>

<th>-k</th>
<td>
enable HTTP keep-alive.
</td>
    </tr><tr>

<th>-d</th>
<td>
Base64 decode POST request content
</td>
    </tr><tr>

<th>-x</th>
<td>
write benchmarkdata-reporting to output file.
</td>
    </tr><tr>

<th>-y</th>
<td>
write data on coverage to output file (must used with -x).
</td>
    </tr><tr>

<th>-z</th>
<td>
use single query file to be distributed between clients.
</td>
    </tr><tr>

<th>-T <em>file</em></th>
<td>
CA certificate file to verify peer against.
Use to benchmark https enabled port. (e.g <em>-T /etc/ssl/certs/ca-bundle.crt</em>)
</td>
    </tr><tr>

<th>-C <em>file</em></th>
<td>
client certificate file name
</td>
    </tr><tr>

<th>-K <em>file</em></th>
<td>
client private key file name
</td>
    </tr><tr>

<th>-D</th>
<td>
use TLS configuration from environment if T/C/K is not used
</td>

    </tr>
  </tbody>
</table>



<h2 id="using-prepare">Preparing query files</h2>
<p>
vespa-fbench uses <em>query files</em>,
which are files where each line is a query following the pattern:
<pre>
/search/?yql=select%20%2A%20from%20sources%20%2A%20where%20sddocname%20contains%20%22music%22%3B
</pre>
When using the -X (HTTP POST) option vespa-fbench expects the following format:
<pre>
/search/
{"yql" : "select * from sources * where sddocname contains music;"}
</pre>
Any line starting with "/" will be taken as an URL path,
with the following lines taken as the content (these lines can NOT start with "/").
With json body payload you also need to specify the content type by <em>-H "Content-Type: application/json" </em>
</p>



<h2 id="using-fbench">Run vespa-fbench</h2>
<p>It is recommended to run multiple tests by changing the value in
<code>-n</code> parameter to measure how the system might sustain
query load and still meet the QPS and/or latency requirements. For
example, starting from 1 client, 10, 20, etc.
</p><p>
A typical vespa-fbench command looks like:
<pre>
$ vespa-fbench -n 10 -q query%03d.txt -s 300 -c 0 -o output%03d.txt -xy test.domain.com 8080
</pre>
A more complex example, using docker, hitting a Vespa Cloud endpoint:
<pre>
$ docker run -v /Users/myself/tmp:/testfiles \
      -w /testfiles --entrypoint '' vespaengine/vespa \
      /opt/vespa/bin/vespa-fbench \
          -C data-plane-public-cert.pem -K data-plane-private-key.pem -T /etc/ssl/certs/ca-bundle.crt \
          -n 10 -q query%03d.txt -o output%03d.txt -xy -s 300 -c 0 \
          myapp.mytenant.aws-us-east-1c.public.vespa.oath.cloud 443
</pre>
This creates 10 clients which will run for 300 seconds (5 minutes). The
<code>-c</code> parameter states that each client will wait for 0
milliseconds between each request. Each client would use a query and
output file given by the given pattern and it's client number,
i.e. client 1 will use query file query001.txt and output file output001.txt.
</p><p>
The options <code>-xy</code> makes vespa-fbench clients output
benchmarking data to it's output files.
</p><p>
It is possible to list several hostnames and ports. The different
hostnames will be distributed to the clients in a round-robin manner,
such that, with two hosts, client 0, 2, &hellip;, 38 would make requests to
the first host while client 1, 3, &hellip;, 39 would make requests to the
second host.
</p><p>
Note that saving all responses to disk might impact the performance of
the benchmarking itself. If only the summary is needed it is
recommended to not use output files.
</p>



<h2 id="using-post">Using vespa-fbench results</h2>
<p>
After running vespa-fbench you will have a summary written to stdout
and an output file from each client.
</p>


<h3 id="results">Understanding benchmarking results</h3>
<p>
After a test run has completed, vespa-fbench outputs various test results.
This section will explain what each of these numbers mean. Notes:
<ul>
  <li>
    'system utilization' provides no information about the Vespa
  system under test and should not be used for benchmarking
  </li><li>
    In some modes of operation, vespa-fbench waits before sending the next query
  </li><li>
    'system utilization' represents the time that vespa-fbench is
    sending queries and waiting for responses. For example,
    a 'system utilization' of 50% means that vespa-fbench is stress testing the system 50% of the time,
    and is doing nothing the remaining 50% of the time
  </li><li>
    Do not run vespa-fbench on the same machine as the container
    or the search node because it will impact the performance of vespa system
  </li><li>
    vespa-fbench latency results include network latency.
    Measure and subtract network latency to obtain the true vespa query latency.
    See also <a href="#results-extended-1">extended results</a> for this info from Vespa
  </li><li>
    If many of the queries return zero results, the average latency will be low</li>
</ul>
</p>


<h3 id="results-basic">Basic results</h3>
<table class="table">
  <thead></thead><tbody>
    <tr>
<th style="width:200px">connection reuse count</th>
<td> This value indicates how many times HTTP
     connections were reused to issue another
     request. Note that this number will only be
     displayed if the -k switch (enable HTTP
     keep-alive) is used.
</td>
    </tr><tr>

<th>clients</th>
<td> Echo of the -n parameter.</td>
    </tr><tr>

<th>cycle time</th>
<td> Echo of the -c parameter.</td>
    </tr><tr>

<th>lower response limit</th>
<td> Echo of the -l parameter.</td>
    </tr><tr>

<th>skipped requests</th>
<td> Number of requests that was skipped
by vespa-fbench. vespa-fbench will typically skip a request if the line containing
the query url exceeds a pre-defined limit. Skipped requests will have
minimal impact on the statistical results.</td>
    </tr><tr>

<th>failed requests</th>
<td> The number of failed requests. A
request will be marked as failed if en error occurred while reading
the result or if the result contained less bytes than 'lower response
limit'.</td>
    </tr><tr>

<th>successful requests</th>
<td> Number of successful
requests. Each performed request is counted as either successful or
failed. Skipped requests (see above) are not performed and therefore
not counted.</td>
    </tr><tr>

<th>cycles not held</th>
<td> Number of cycles not held. The cycle
time is specified with the -c parameter. It defines how often a client
should perform a new request. However, a client may not perform
another request before the result from the previous request has been
obtained. Whenever a client is unable to initiate a new request 'on
time' due to not being finished with the previous request, this value
will be increased.</td>
    </tr><tr>

<th>minimum response time</th>
<td> The minimum response time. The
response time is measured as the time period from just before the
request is sent to the server, till the result is obtained from the
server.</td>
    </tr><tr>

<th>maximum response time</th>
<td> The maximum response time. The
response time is measured as the time period from just before the
request is sent to the server, till the result is obtained from the
server.</td>
    </tr><tr>

<th>average response time</th>
<td> The average response time. The
response time is measured as the time period from just before the
request is sent to the server, till the result is obtained from the
server.</td>
    </tr><tr>

<th>X percentile</th>
<td> The X percentile of the response time
samples; a value selected such that X percent of the response time
samples are below this value. In order to calculate percentiles, a
histogram of response times is maintained for each client at runtime
and merged after the test run ends. If a percentile value exceeds the
upper bound of this histogram, it will be approximated (and thus less
accurate) and marked with '(approx)'.</td>
    </tr><tr>

<th>actual query rate</th>
<td> The average number of queries per
second; QPS.</td>
    </tr><tr>

<th>utilization</th>
<td> The percentage of time used waiting for
the server to complete (successful) requests. Note that if a request
fails, the utilization will drop since the client has 'wasted' the
time spent on the failed request.</td>
    </tr><tr>

<th>zero hit queries</th>
<td>The number of queries that gave zero hits in Vespa</td>
    </tr>
  </tbody>
</table>


<h3 id="results-extended">Extended results</h3>

<h4 id="results-extended-1"><code>-x</code> Activate benchmarkdata-reporting</h4>
<p>
This results will be added to the output file
if the <code>-x</code> switch is active(activate benchmarkdata-reporting) is used.
</p>

<table class="table">
  <thead></thead><tbody>
    <tr>
      <th style="width:200px">NumHits</th>
<td>Number of hits returned</td>
    </tr><tr>

<th>NumFastHits</th>
<td>Number of actual document hits returned</td>
    </tr><tr>

<th>TotalHitCount</th>
<td>Total number of hits for query</td>
    </tr><tr>

<th>QueryHits</th>
<td>Hits as specified in query</td>
    </tr><tr>

<th>QueryOffset</th>
<td>Offset as specified in query</td>
    </tr><tr>

<th>NumErrors</th>
<td>Number of error hits returned</td>
    </tr><tr>

<th>NumGroupHits</th>
<td>Number of grouping hits returned</td>
    </tr><tr>

<th>SearchTime</th>
<td>Time used for searching. Entire query time for one phase search, first phase for
two-phase search</td>
    </tr><tr>

<th>AttributeFetchTime</th>
<td>Time used for attribute fetching, or 0 for one phase search</td>
    </tr><tr>

<th>FillTime</th>
<td>Time used for summary fetching, or 0 for one phase search</td>
    </tr>
  </tbody>
</table>

<h4 id="results-extended-2"><code>-y</code> Activate additional data on coverage</h4>
<p>
This uses the report coverage query feature.
These results will be added to the output file if the <code>-y</code> switch is active.
</p>
<table class="table">
  <thead></thead><tbody>
    <tr>
      <th style="width:200px">DocsSearched</th>
<td>Total number of documents in nodes searched</td>
    </tr><tr>

<th>NodesSearched</th>
<td>Total number of search nodes which were used</td>
    </tr><tr>

<th>FullCoverage</th>
<td>1 if true, 0 if false</td>
    </tr>
  </tbody>
</table>



<h2 id="utilities">Utilities</h2>
<table class="table">
<tr>
    <th>vespa-fbench-filter-file</th>
    <td>
<pre>
usage: vespa-fbench-filter-file [-a] [-h] [-m maxLineSize]

Read concatenated fastserver logs from stdin and write
extracted query urls to stdout.

 -a       : all parameters to the original query urls are preserved.
            If the -a switch is not given, only 'query' and 'type'
            parameters are kept in the extracted query urls.
 -h       : print this usage information.
 -m &lt;num&gt; : max line size for input/output lines.
            Can not be less than the default [10240]
</pre>
    </td>
</tr><tr>
    <th>vespa-fbench-geturl</th>
    <td>
<pre>
usage: vespa-fbench-geturl &lt;host&gt; &lt;port&gt; &lt;url&gt;
</pre>
    </td>
</tr><tr>
    <th>vespa-fbench-result-filter.pl</th>
    <td>
<pre>

</pre>
    </td>
</tr><tr>
    <th>vespa-fbench-split-file</th>
    <td>
<pre>
usage: vespa-fbench-split-file [-p pattern] [-m maxLineSize] &lt;numparts&gt; [&lt;file&gt;]

Reads from &lt;file&gt; (stdin if &lt;file&gt; is not given) and
randomly distributes each line between &lt;numpart&gt; output
files. The names of the output files are generated by
combining the &lt;pattern&gt; with sequential numbers using
the sprintf function.

 -p pattern : output name pattern ['query%03d.txt']
 -m &lt;num&gt;   : max line size for input/output lines.
              Can not be less than the default [10240]
 &lt;numparts&gt; : number of output files to generate.
</pre>
    </td>
</tr>
</table>
